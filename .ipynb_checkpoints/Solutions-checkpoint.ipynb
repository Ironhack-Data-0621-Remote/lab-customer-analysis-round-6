{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab | Customer Analysis Round 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we still keep using the marketing_customer_analysis.csv file that you can find in the files_for_lab folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using the marketing_customer_analysis.csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import OneHotEncoder, Normalizer, StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "data = pd.read_csv('files_for_lab/csv_files/marketing_customer_analysis.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already done in the round 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dfheaders(df):\n",
    "    df.rename(columns={'Customer':'id', 'EmploymentStatus':'employment_status'}, inplace=True)\n",
    "    df.columns = df.columns.str.lower().str.strip().str.replace(' ', '_')\n",
    "    return df\n",
    "\n",
    "# using the 2 operations together only works when removing the 'df=' infront of the first satemment. Why?\n",
    "# the first operation doesnt work at all in a function without the inplace parameter. Outside of a function it does work. Why?\n",
    "\n",
    "clean_dfheaders(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['effective_to_date'] = pd.to_datetime(data['effective_to_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done in the round 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Further processing...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- X-y split. (done)\n",
    "- Normalize (numerical). (done)\n",
    "- One Hot/Label Encoding (categorical).\n",
    "- Concat DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**X-Y Split** If you have not done it, you have you take in count that the target will be `total_claim_amount`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = list(data1.select_dtypes(include=[np.number]).columns.values)\n",
    "\n",
    "# removing outliers where it makes sense\n",
    "outl_col1 = ['customer_lifetime_value', 'monthly_premium_auto', 'number_of_policies', 'total_claim_amount']\n",
    "\n",
    "for col in outl_col:\n",
    "    iqr = np.percentile(data1[col],75) - np.percentile(data1[col],25)\n",
    "    upper_limit = np.percentile(data1[col],75) + 1.5*iqr\n",
    "    lower_limit = np.percentile(data1[col],25) - 1.5*iqr\n",
    "    if col == 'number_of_policies':\n",
    "        data1.loc[data1[col] > upper_limit, col] = upper_limit\n",
    "        data1.loc[data1[col] < lower_limit, col] = lower_limit\n",
    "    else:\n",
    "        data1.loc[data1[col] > upper_limit, col] = data1[col].median()\n",
    "        data1.loc[data1[col] < lower_limit, col] = data1[col].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for values <= 0 and replacing them before tranforming\n",
    "for col in number_col:\n",
    "    neg_val = len(data1[data1[col] < 0])\n",
    "    zero_val = len(data1[data1[col] == 0])\n",
    "     \n",
    "    if neg_val > 0:\n",
    "        print('Negative values in', col, ':', neg_val)\n",
    "    elif zero_val > 0:\n",
    "        print('Zeros in', col, ':', zero_val)\n",
    "    else:\n",
    "        print('Column', col, 'is ok.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalize (numerical)** If you have not done it yet, you can define a function using `StandardScaler`from sklearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t = data1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform\n",
    "repl_col = ['income', 'months_since_last_claim', 'months_since_policy_inception']\n",
    "\n",
    "for col in repl_col:\n",
    "    data_t[col] = np.where(data_t[col] == 0, data_t[col].median(), data_t[col])\n",
    "    \n",
    "trans_col = ['customer_lifetime_value', 'income', 'monthly_premium_auto', 'months_since_last_claim', 'months_since_policy_inception']\n",
    "\n",
    "for col in trans_col:\n",
    "    transformed_col, _ci = stats.boxcox(data_t[col])\n",
    "    data_t[col] = transformed_col\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.distplot(data_t[col])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x-y split\n",
    "t_num = list(data_t.select_dtypes(include=[np.number]).columns.values)\n",
    "data_t.set_index('id', inplace=True)\n",
    "t_object = list(data_t.select_dtypes(include=[np.object]).columns.values)\n",
    "\n",
    "t_drop = t_object + [t_num[7]] + ['effective_to_date']\n",
    "x_t = data_t.drop(t_drop, axis=1)\n",
    "y = data_t['total_claim_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize and Standardize\n",
    "transformer = Normalizer().fit(x_t)\n",
    "x_normalized = transformer.transform(x_t)\n",
    "data_sn = pd.DataFrame(x_normalized)\n",
    "\n",
    "transformer = StandardScaler().fit(data_sn)\n",
    "x_standardized = transformer.transform(data_sn)\n",
    "data_sn = pd.DataFrame(x_standardized)\n",
    "\n",
    "sn_col = ['customer_lifetime_value', 'income', 'monthly_premium_auto', 'months_since_last_claim', 'months_since_policy_inception', 'number_of_open_complaints', 'number_of_policies']\n",
    "\n",
    "for idx, col in enumerate(sn_col):\n",
    "    data_sn.rename(columns={idx:col}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One Hot/Label Encoding (categorical)** Try one of the two options learned in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cat = data_t.select_dtypes(include = [np.object])\n",
    "\n",
    "for col in t_object:\n",
    "    print(x_cat[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data_t.select_dtypes(include=[np.object]).columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1h = x_cat.drop(['coverage', 'education', 'vehicle_size'], axis=1)\n",
    "x_label1 = x_cat['coverage']\n",
    "x_label2 = x_cat['education']\n",
    "x_label3 = x_cat['vehicle_size']\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='error', drop='first')\n",
    "encoder.fit(x_1h)\n",
    "\n",
    "encoded = encoder.transform(x_1h).toarray()\n",
    "data_1h = pd.DataFrame(encoded)\n",
    "# to do: data_1h.columns = encoder.categories_\n",
    "\n",
    "le1 = LabelEncoder().fit(x_label1).transform(x_label1)\n",
    "le2 = LabelEncoder().fit(x_label2).transform(x_label2)\n",
    "le3 = LabelEncoder().fit(x_label3).transform(x_label3)\n",
    "\n",
    "data_le1 = pd.DataFrame(le1)\n",
    "data_le1.columns = ['coverage']\n",
    "data_le2 = pd.DataFrame(le2)\n",
    "data_le2.columns = ['education']\n",
    "data_le3 = pd.DataFrame(le3)\n",
    "data_le2.columns = ['vehicle_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concat DataFrames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate([data_sn, data_1h, data_le1, data_le2, data_le3], axis=1)\n",
    "# losing column names\n",
    "\n",
    "data_x = pd.DataFrame(x)\n",
    "data_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train-test split.\n",
    "- Apply linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train-test split** Divide your data in a train part and a test part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_x\n",
    "y = data_t['total_claim_amount']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply linear regression** For this question you can use `statsmodels` or `sklearn` libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Description:\n",
    "R2.\n",
    "MSE.\n",
    "RMSE.\n",
    "MAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get R2 from the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R2:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get MSE from the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, predictions, squared=True)\n",
    "print(\"MSE:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get RMSE from the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get MAE from the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(\"MAE:\", mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3Brew",
   "language": "python",
   "name": "python3brew"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
